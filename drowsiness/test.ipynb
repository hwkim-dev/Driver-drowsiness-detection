{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting deepsparse[yolov8]\n",
      "  Using cached deepsparse-1.7.1.tar.gz (46.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Ã— Getting requirements to build wheel did not run successfully.\n",
      "  â”‚ exit code: 1\n",
      "  â•°â”€> [22 lines of output]\n",
      "      Loaded version 1.7.1 from C:\\Users\\hwKIM\\AppData\\Local\\Temp\\pip-install-tc6mu_lh\\deepsparse_2f547ecd865e49618e1318599f1b2c1e\\src\\deepsparse\\version.py\n",
      "      Traceback (most recent call last):\n",
      "        File \"C:\\Users\\hwKIM\\anaconda3\\envs\\dLproj\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 353, in <module>\n",
      "          main()\n",
      "        File \"C:\\Users\\hwKIM\\anaconda3\\envs\\dLproj\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 335, in main\n",
      "          json_out['return_val'] = hook(**hook_input['kwargs'])\n",
      "                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\hwKIM\\anaconda3\\envs\\dLproj\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\", line 118, in get_requires_for_build_wheel\n",
      "          return hook(config_settings)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\hwKIM\\AppData\\Local\\Temp\\pip-build-env-98eli3wg\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 325, in get_requires_for_build_wheel\n",
      "          return self._get_build_requires(config_settings, requirements=['wheel'])\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        File \"C:\\Users\\hwKIM\\AppData\\Local\\Temp\\pip-build-env-98eli3wg\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 295, in _get_build_requires\n",
      "          self.run_setup()\n",
      "        File \"C:\\Users\\hwKIM\\AppData\\Local\\Temp\\pip-build-env-98eli3wg\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 487, in run_setup\n",
      "          super().run_setup(setup_script=setup_script)\n",
      "        File \"C:\\Users\\hwKIM\\AppData\\Local\\Temp\\pip-build-env-98eli3wg\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\", line 311, in run_setup\n",
      "          exec(code, locals())\n",
      "        File \"<string>\", line 220, in <module>\n",
      "        File \"<string>\", line 181, in _check_supported_system\n",
      "      OSError: Native Windows is currently unsupported for DeepSparse. Please run on a Linux system or within a Linux container on Windows. More info can be found in our docs here: https://docs.neuralmagic.com/deepsparse/source/hardware.html\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Ã— Getting requirements to build wheel did not run successfully.\n",
      "â”‚ exit code: 1\n",
      "â•°â”€> See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n"
     ]
    }
   ],
   "source": [
    "!pip install deepsparse[yolov8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.8 ðŸš€ Python-3.11.9 torch-2.3.0 CPU (13th Gen Intel Core(TM) i5-13420H)\n",
      "Model summary (fused): 168 layers, 11127906 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best(9).pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (21.5 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "\n",
      "  Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\hwkim\\anaconda3\\envs\\dlproj\\lib\\site-packages (from onnx>=1.12.0) (1.24.3)\n",
      "\n",
      "Collecting protobuf>=3.20.2 (from onnx>=1.12.0)\n",
      "\n",
      "  Downloading protobuf-5.27.0-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "\n",
      "Downloading onnx-1.16.1-cp311-cp311-win_amd64.whl (14.4 MB)\n",
      "\n",
      "   ---------------------------------------- 0.0/14.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.4 MB 1.3 MB/s eta 0:00:12\n",
      "    --------------------------------------- 0.2/14.4 MB 2.3 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.6/14.4 MB 5.1 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 1.1/14.4 MB 6.3 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 1.5/14.4 MB 6.9 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 1.9/14.4 MB 6.9 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 2.5/14.4 MB 7.5 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 3.4/14.4 MB 8.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 3.8/14.4 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 4.4/14.4 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.9/14.4 MB 9.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 8.4 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 5.0/14.4 MB 8.4 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.5/14.4 MB 5.0 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 5.7/14.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.8/14.4 MB 4.9 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.2/14.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 6.4/14.4 MB 5.0 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 6.8/14.4 MB 5.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.1/14.4 MB 5.2 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 7.6/14.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.0/14.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 8.2/14.4 MB 5.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 8.5/14.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 8.7/14.4 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 9.1/14.4 MB 5.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 9.5/14.4 MB 5.5 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 9.9/14.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 10.2/14.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 10.7/14.4 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 11.0/14.4 MB 5.8 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 11.3/14.4 MB 5.7 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 11.6/14.4 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.1/14.4 MB 5.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 12.4/14.4 MB 5.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 12.8/14.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.1/14.4 MB 5.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.4/14.4 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.7/14.4 MB 5.5 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.4 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.4/14.4 MB 5.4 MB/s eta 0:00:00\n",
      "\n",
      "Downloading protobuf-5.27.0-cp310-abi3-win_amd64.whl (426 kB)\n",
      "\n",
      "   ---------------------------------------- 0.0/426.9 kB ? eta -:--:--\n",
      "   ---------------------------------------  419.8/426.9 kB 8.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 426.9/426.9 kB 6.6 MB/s eta 0:00:00\n",
      "\n",
      "Installing collected packages: protobuf, onnx\n",
      "\n",
      "Successfully installed onnx-1.16.1 protobuf-5.27.0\n",
      "\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success âœ… 12.8s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âš ï¸ \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.1 opset 13...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success âœ… 14.6s, saved as 'best(9).onnx' (42.7 MB)\n",
      "\n",
      "Export complete (18.0s)\n",
      "Results saved to \u001b[1mC:\\D\\DL_proj\\rngus\u001b[0m\n",
      "Predict:         yolo predict task=detect model=best(9).onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=best(9).onnx imgsz=640 data=data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
     ]
    }
   ],
   "source": [
    "!yolo task=detect mode=export model=best(9).pt format=onnx opset=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.2.8 ðŸš€ Python-3.11.9 torch-2.3.0 CPU (13th Gen Intel Core(TM) i5-13420H)\n",
      "Model summary (fused): 168 layers, 11127906 parameters, 0 gradients\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'best(9).pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 10, 8400) (21.5 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.1.0-15008-f4afc983258-releases/2024/1...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success âœ… 3.7s, saved as 'best(9)_openvino_model\\' (42.8 MB)\n",
      "\n",
      "Export complete (11.6s)\n",
      "Results saved to \u001b[1mC:\\D\\DL_proj\\rngus\u001b[0m\n",
      "Predict:         yolo predict task=detect model=best(9)_openvino_model imgsz=640  \n",
      "Validate:        yolo val task=detect model=best(9)_openvino_model imgsz=640 data=data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/export\n"
     ]
    }
   ],
   "source": [
    "!yolo export model=best(9).pt format=openvino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Unable to automatically guess model task, assuming 'task=detect'. Explicitly define task for your model, i.e. 'task=detect', 'segment', 'classify','pose' or 'obb'.\n",
      "Loading best(9).onnx for ONNX Runtime inference...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnxruntime'] not found, attempting AutoUpdate...\n",
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.18.0-cp311-cp311-win_amd64.whl.metadata (4.4 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: numpy>=1.24.2 in c:\\users\\hwkim\\anaconda3\\envs\\dlproj\\lib\\site-packages (from onnxruntime) (1.24.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\hwkim\\anaconda3\\envs\\dlproj\\lib\\site-packages (from onnxruntime) (24.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hwkim\\anaconda3\\envs\\dlproj\\lib\\site-packages (from onnxruntime) (5.27.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\hwkim\\anaconda3\\envs\\dlproj\\lib\\site-packages (from onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hwkim\\anaconda3\\envs\\dlproj\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime)\n",
      "  Downloading pyreadline3-3.4.1-py3-none-any.whl.metadata (2.0 kB)\n",
      "Downloading onnxruntime-1.18.0-cp311-cp311-win_amd64.whl (5.6 MB)\n",
      "   ---------------------------------------- 5.6/5.6 MB 9.7 MB/s eta 0:00:00\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "   ---------------------------------------- 46.0/46.0 kB ? eta 0:00:00\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "   ---------------------------------------- 86.8/86.8 kB 5.1 MB/s eta 0:00:00\n",
      "Downloading pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
      "   ---------------------------------------- 95.2/95.2 kB ? eta 0:00:00\n",
      "Installing collected packages: pyreadline3, flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 onnxruntime-1.18.0 pyreadline3-3.4.1\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  7.1s, installed 1 package: ['onnxruntime']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "0: 640x640 1 Face, 1 Leye open, 1 Reye open, 1 Mouth, 184.7ms\n",
      "Speed: 14.9ms preprocess, 184.7ms inference, 1466.9ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Get the boxes and track IDs\u001b[39;00m\n\u001b[0;32m     30\u001b[0m boxes \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mboxes\u001b[38;5;241m.\u001b[39mxywh\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m---> 31\u001b[0m track_ids \u001b[38;5;241m=\u001b[39m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint\u001b[49m()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Visualize the results on the frame\u001b[39;00m\n\u001b[0;32m     34\u001b[0m annotated_frame \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'int'"
     ]
    }
   ],
   "source": [
    "#from deepsparse import Pipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model_path = \"best(9).onnx\"\n",
    "\n",
    "#yolo_pipeline = Pipeline.create(task=\"yolov8\", model_path=model_path)\n",
    "model = YOLO(model_path)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "TARGET_WIDTH = 640\n",
    "TARGET_HEIGHT = 480\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, TARGET_WIDTH)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, TARGET_HEIGHT)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "        results = model(frame)\n",
    "\n",
    "        # Get the boxes and track IDs\n",
    "        boxes = results[0].boxes.xywh.cpu()\n",
    "        track_ids = results[0].boxes.id.int().cpu().tolist()\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Plot the tracks\n",
    "        for box, track_id in zip(boxes, track_ids):\n",
    "            x, y, w, h = box\n",
    "            track = track_history[track_id]\n",
    "            track.append((float(x), float(y)))  # x, y center point\n",
    "            if len(track) > 30:  # retain 90 tracks for 90 frames\n",
    "                track.pop(0)\n",
    "\n",
    "            # Draw the tracking lines\n",
    "            points = np.hstack(track).astype(np.int32).reshape((-1, 1, 2))\n",
    "            cv2.polylines(annotated_frame, [points], isClosed=False, color=(230, 230, 230), thickness=10)\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "model = YOLO(\"best(9).pt\")\n",
    "\n",
    "# Export the model to NCNN format\n",
    "model.export(format=\"ncnn\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dLproj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
